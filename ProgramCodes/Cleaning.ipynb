{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0835b43-789d-47ee-af8c-a97bd756b371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining number of tokens: 59\n",
      "Filtered dataset shape: (5251176, 15)\n",
      "sales_datetime             0\n",
      "id                         0\n",
      "asset.id                   0\n",
      "asset.name                 0\n",
      "asset.collection.name      0\n",
      "total_price                0\n",
      "payment_token.name         0\n",
      "payment_token.usd_price    0\n",
      "asset.num_sales            0\n",
      "seller.address             0\n",
      "seller.user.username       0\n",
      "winner_account.address     0\n",
      "Category                   0\n",
      "usd_price                  0\n",
      "dtype: int64\n",
      "Cleaned dataset successfully saved as 'cleaned_dataset.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#  Load the dataset\n",
    "df = pd.read_csv(\"opensea_nft_sales.csv\", low_memory=False)\n",
    "\n",
    "#  Remove duplicate records\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "#  Filter out rarely used payment tokens (less than 50 occurrences)\n",
    "min_threshold = 50\n",
    "token_counts = df['payment_token.name'].value_counts(dropna=False)\n",
    "filtered_tokens = token_counts[token_counts >= min_threshold].index\n",
    "df = df[df['payment_token.name'].isin(filtered_tokens)]\n",
    "\n",
    "print(f\"Remaining number of tokens: {len(filtered_tokens)}\")\n",
    "print(f\"Filtered dataset shape: {df.shape}\")\n",
    "\n",
    "#  Fill missing asset names with contextual placeholders\n",
    "df['asset.name'] = df.apply(\n",
    "    lambda row: f\"Unnamed in {row['asset.collection.name']}\" if pd.isna(row['asset.name']) and pd.notna(row['asset.collection.name'])\n",
    "    else (\"Unnamed Asset\" if pd.isna(row['asset.name']) else row['asset.name']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "#  Fill missing collection names based on asset name or default to \"Unknown Collection\"\n",
    "df['asset.collection.name'] = df.apply(\n",
    "    lambda row: f\"Collection of {row['asset.name']}\" if pd.isna(row['asset.collection.name']) and pd.notna(row['asset.name'])\n",
    "    else (\"Unknown Collection\" if pd.isna(row['asset.collection.name']) else row['asset.collection.name']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "#  Drop irrelevant or unused columns\n",
    "df.drop(columns=['asset.collection.short_description', 'asset.permalink'], inplace=True)\n",
    "\n",
    "#  Fill missing payment token names with the most common one\n",
    "most_common_token = df['payment_token.name'].mode()[0]\n",
    "df['payment_token.name'] = df['payment_token.name'].fillna(most_common_token)\n",
    "\n",
    "#  Standardize token names using a mapping dictionary\n",
    "token_map = {\n",
    "    'Ether': 'ETH',\n",
    "    'Wrapped Ether': 'WETH',\n",
    "    'USD Coin': 'USDC',\n",
    "    'Dai Stablecoin': 'DAI',\n",
    "    'Decentraland MANA': 'MANA',\n",
    "    'Matic Token': 'MATIC',\n",
    "    'Enjin Token': 'ENJ',\n",
    "    'Gala': 'GALA'\n",
    "    # Can be extended as needed\n",
    "}\n",
    "df['payment_token.name'] = df['payment_token.name'].replace(token_map)\n",
    "\n",
    "#  Convert total_price from string to float and from Wei to ETH\n",
    "df['total_price'] = pd.to_numeric(df['total_price'], errors='coerce') / 1e18\n",
    "\n",
    "#  Load token price reference file\n",
    "token_price_df = pd.read_csv(\"token_prices.csv\")\n",
    "token_price_df.columns = token_price_df.columns.str.strip()\n",
    "price_dict = dict(zip(token_price_df['token_name'], token_price_df['usd_price']))\n",
    "\n",
    "#  Keep only transactions with known token prices\n",
    "df = df[df['payment_token.name'].isin(price_dict.keys())]\n",
    "\n",
    "#  Calculate the USD equivalent of each transaction\n",
    "df['payment_token.usd_price'] = df['payment_token.name'].map(price_dict)\n",
    "df['usd_price'] = df['total_price'] * df['payment_token.usd_price']\n",
    "\n",
    "#  Drop rows where USD price could not be calculated\n",
    "df = df[df['usd_price'].notna()]\n",
    "\n",
    "#  Match Ethereum addresses to usernames (or generate placeholder usernames)\n",
    "address_to_username = df.dropna(subset=['seller.user.username']).drop_duplicates('seller.address')[['seller.address', 'seller.user.username']]\n",
    "address_to_username_map = dict(zip(address_to_username['seller.address'], address_to_username['seller.user.username']))\n",
    "\n",
    "def get_or_generate_username(row):\n",
    "    address = row['seller.address']\n",
    "    if pd.notna(row['seller.user.username']):\n",
    "        return row['seller.user.username']\n",
    "    elif address in address_to_username_map:\n",
    "        return address_to_username_map[address]\n",
    "    else:\n",
    "        return f\"user_{str(address)[2:8]}\"\n",
    "\n",
    "df['seller.user.username'] = df.apply(get_or_generate_username, axis=1)\n",
    "\n",
    "#  Format addresses to make them readable (e.g., Seller_xxxxx, Buyer_xxxxx)\n",
    "df['seller.address'] = df['seller.address'].astype(str).apply(lambda x: f\"Seller_{x[:5]}\" if x.lower() != 'nan' else \"Unknown\")\n",
    "df['winner_account.address'] = df['winner_account.address'].astype(str).apply(lambda x: f\"Buyer_{x[:5]}\" if x.lower() != 'nan' else \"Unknown\")\n",
    "\n",
    "#  Display missing value counts after cleaning\n",
    "print(df.isna().sum())\n",
    "\n",
    "#  Save cleaned dataset\n",
    "df.to_csv(\"cleaned_dataset2.csv\", index=False)\n",
    "print(\"Cleaned dataset successfully saved as 'cleaned_dataset.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bbdfc25-31b3-420a-8039-04204f324739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kalan token sayısı: 59\n",
      "Filtrelenmiş veri boyutu: (5251176, 15)\n",
      "sales_datetime             0\n",
      "id                         0\n",
      "asset.id                   0\n",
      "asset.name                 0\n",
      "asset.collection.name      0\n",
      "total_price                0\n",
      "payment_token.name         0\n",
      "payment_token.usd_price    0\n",
      "asset.num_sales            0\n",
      "seller.address             0\n",
      "seller.user.username       0\n",
      "winner_account.address     0\n",
      "Category                   0\n",
      "usd_price                  0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"opensea_nft_sales.csv\", low_memory=False)\n",
    "\n",
    "\n",
    "df.drop_duplicates(inplace=True)\n",
    "min_threshold = 50\n",
    "token_counts = df['payment_token.name'].value_counts(dropna=False)\n",
    "filtered_tokens = token_counts[token_counts >= min_threshold].index\n",
    "df = df[df['payment_token.name'].isin(filtered_tokens)]\n",
    "\n",
    "print(f\"Kalan token sayısı: {len(filtered_tokens)}\")\n",
    "print(f\"Filtrelenmiş veri boyutu: {df.shape}\")\n",
    "\n",
    "#1\n",
    "df['asset.name'] = df.apply(\n",
    "    lambda row: f\"Unnamed in {row['asset.collection.name']}\" if pd.isna(row['asset.name']) and pd.notna(row['asset.collection.name'])\n",
    "    else (\"Unnamed Asset\" if pd.isna(row['asset.name']) else row['asset.name']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "#2\n",
    "\n",
    "df['asset.collection.name'] = df.apply(\n",
    "    lambda row: f\"Collection of {row['asset.name']}\" if pd.isna(row['asset.collection.name']) and pd.notna(row['asset.name'])\n",
    "    else (\"Unknown Collection\" if pd.isna(row['asset.collection.name']) else row['asset.collection.name']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "df.drop(columns=['asset.collection.short_description'], inplace=True)\n",
    "df.drop(columns=['asset.permalink'], inplace=True)\n",
    "\n",
    "\n",
    "# 1. Eksik token adlarını en sık geçenle doldur\n",
    "most_common_token = df['payment_token.name'].mode()[0]\n",
    "df['payment_token.name'] = df['payment_token.name'].fillna(most_common_token)\n",
    "\n",
    "# 2. Toplam fiyatı float yap\n",
    "df['total_price'] = df['total_price'].astype(float)\n",
    "df['total_price'] = df['total_price'] / 1e18\n",
    "\n",
    "\n",
    "# 3. Token fiyatlarını oku ve eşleştir\n",
    "token_price_df = pd.read_csv(\"token_prices.csv\")\n",
    "token_price_df.columns = token_price_df.columns.str.strip()  # boşlukları temizle\n",
    "price_dict = dict(zip(token_price_df['token_name'], token_price_df['usd_price']))\n",
    "\n",
    "# 4. Sadece bilinen token'ları al\n",
    "df = df[df['payment_token.name'].isin(price_dict.keys())]\n",
    "\n",
    "# 5. Token başına USD fiyatı doğru olarak ata (çarpma yok!)\n",
    "df['payment_token.usd_price'] = df['payment_token.name'].map(price_dict)\n",
    "\n",
    "# 6. USD cinsinden toplam fiyatı hesapla\n",
    "df['usd_price'] = df['total_price'] * df['payment_token.usd_price']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Adres - username match\n",
    "address_to_username = df.dropna(subset=['seller.user.username']).drop_duplicates('seller.address')[['seller.address', 'seller.user.username']]\n",
    "address_to_username_map = dict(zip(address_to_username['seller.address'], address_to_username['seller.user.username']))\n",
    "\n",
    "#seller address - username match\n",
    "def get_or_generate_username(row):\n",
    "    address = row['seller.address']\n",
    "    if pd.notna(row['seller.user.username']):\n",
    "        return row['seller.user.username']\n",
    "    elif address in address_to_username_map:\n",
    "        return address_to_username_map[address]\n",
    "    else:\n",
    "        return f\"user_{str(address)[2:8]}\"  # or random/uuid vs.\n",
    "\n",
    "df['seller.user.username'] = df.apply(get_or_generate_username, axis=1)\n",
    "\n",
    "# Adresleri stringe çevir\n",
    "df['seller.address'] = df['seller.address'].astype(str)\n",
    "df['winner_account.address'] = df['winner_account.address'].astype(str)\n",
    "\n",
    "# Etiketleri oluştur\n",
    "df['seller.address'] = df['seller.address'].apply(lambda x: f\"Seller_{x[:5]}\" if x.lower() != 'nan' else \"Unknown\")\n",
    "df['winner_account.address'] = df['winner_account.address'].apply(lambda x: f\"Buyer_{x[:5]}\" if x.lower() != 'nan' else \"Unknown\")\n",
    "\n",
    "\n",
    "print(df.isna().sum())\n",
    "\n",
    "# Save\n",
    "df.to_csv(\"cleaned_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32e1bd9-778f-4359-8d02-e55ea6696046",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
